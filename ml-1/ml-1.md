# Основные метрики качества моделей классификации и регрессии

Качество работы алгоримтов классификации оценивается по составляющим матрицы ошибок:

Confusion matrix: y_pred=(1,0) x y_true=(1,0)

* True Positive
* False Positive
* False Negative
* True Negative

## Accuracy (доля правильных ответов)

acc = (TP + TN) / (TP + TN + FP + FN)

+ интуитивно понятная

- неприменима при дисбалансе положительных и отрицательных сэмплов в датасете, когда при (TP + FP) --> 0 acc остаётся высокой


## Precision (точность)

precision = TP / (TP + FP) - какое число положительных ответов являются правильными

+ позволяет контролировать рост ложных положительных срабатываний

- т.к. не содержит TN и FN, неприменима при дисбалансе в датасете


## Recall (чувствительность)

recall = TP / (TP + FN) - доля верно определённых как положительные из числа всех реально положительных, качество угадывания положительных ответов

+ позволяет контролировать полноту положительной классификации

- не учитывает всех составляющих, чувствительна к дисбалансу


## Specificity (специфичность)

specificity = TN / (TN + FP) - доля верно определённых как отрицательные из числа всех отрицательных

+ позволяет контролировать качество игнорирования

- чувствительна к дисбалансу

## F-мера

F = 2 * Precision * Recall / (Precision + Recall) 

+ комплексная оценка,  достигающая максимума при максимуме обеих величин Precision и Recall

- не учитывает FP